{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuJma6oLNnyUOdGUFf2Dmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naimdsaiki/Machine-Learning/blob/main/Domestic_Opening_Week_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9Y3qSEi_4by",
        "outputId": "e06a72a6-58b7-498b-9fee-3cfdbe9070ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from Box Office Mojo...\n",
            "Successfully scraped 0 movies.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "Data saved to 'domestic_openings.csv'\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 1. SETUP THE URL AND HEADERS\n",
        "# We target the \"All Time Domestic Opening Weekends\" chart\n",
        "url = \"https://www.boxofficemojo.com/chart/top_opening_weekend/\"\n",
        "\n",
        "# HEADERS are crucial! They make our script look like a real browser (Chrome)\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "print(\"Fetching data from Box Office Mojo...\")\n",
        "\n",
        "# 2. REQUEST THE PAGE\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "# Check if successful\n",
        "if response.status_code != 200:\n",
        "    print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
        "else:\n",
        "    # 3. PARSE HTML\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find the main table (usually has a specific class or is the first table)\n",
        "    # Box Office Mojo tables are usually inside a div with class 'a-section'\n",
        "    table = soup.find('table')\n",
        "\n",
        "    movie_data = []\n",
        "\n",
        "    # 4. EXTRACT DATA ROW BY ROW\n",
        "    # We skip the first row usually because it's the header\n",
        "    rows = table.find_all('tr')[1:]\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "\n",
        "        # Ensure the row has data (some are empty spacers)\n",
        "        if len(cols) > 2:\n",
        "            title = cols[1].get_text(strip=True)\n",
        "            opening_str = cols[2].get_text(strip=True)\n",
        "            total_gross_str = cols[4].get_text(strip=True) # Lifetime domestic\n",
        "\n",
        "            # Clean the currency strings immediately (remove '$' and ',')\n",
        "            try:\n",
        "                opening_val = float(opening_str.replace('$', '').replace(',', ''))\n",
        "                total_val = float(total_gross_str.replace('$', '').replace(',', ''))\n",
        "            except ValueError:\n",
        "                continue # Skip if data is messy\n",
        "\n",
        "            movie_data.append({\n",
        "                'title': title,\n",
        "                'domestic_opening': opening_val,\n",
        "                'domestic_lifetime': total_val\n",
        "            })\n",
        "\n",
        "    # 5. CREATE DATAFRAME\n",
        "    df_mojo = pd.DataFrame(movie_data)\n",
        "\n",
        "    print(f\"Successfully scraped {len(df_mojo)} movies.\")\n",
        "    print(df_mojo.head())\n",
        "\n",
        "    # 6. SAVE TO CSV\n",
        "    df_mojo.to_csv('domestic_openings.csv', index=False)\n",
        "    print(\"Data saved to 'domestic_openings.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# 1. SETUP URL & HEADERS\n",
        "url = \"https://www.boxofficemojo.com/chart/top_opening_weekend/\"\n",
        "# We still need headers to look like a real browser\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "print(\"Fetching data...\")\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # 2. USE PANDAS TO FIND ALL TABLES\n",
        "    # This returns a list of all tables found on the page\n",
        "    tables = pd.read_html(response.text)\n",
        "\n",
        "    print(f\"Found {len(tables)} tables on the page.\")\n",
        "\n",
        "    # 3. IDENTIFY THE CORRECT TABLE\n",
        "    # We loop through them to find the one with 'Opening' and 'Total Gross' columns\n",
        "    df_mojo = None\n",
        "    for t in tables:\n",
        "        if 'Opening' in t.columns and 'Total Gross' in t.columns:\n",
        "            df_mojo = t\n",
        "            break\n",
        "\n",
        "    if df_mojo is not None:\n",
        "        print(\"Success! Data table found.\")\n",
        "\n",
        "        # 4. CLEAN THE DATA\n",
        "        # Rename 'Release' to 'title' to match your other dataset\n",
        "        df_mojo = df_mojo.rename(columns={'Release': 'title', 'Opening': 'domestic_opening'})\n",
        "\n",
        "        # Remove '$', ',' and convert to numeric\n",
        "        # We use regex=True to replace patterns\n",
        "        cols_to_clean = ['domestic_opening', 'Total Gross']\n",
        "        for col in cols_to_clean:\n",
        "            df_mojo[col] = df_mojo[col].astype(str).str.replace(r'[$,]', '', regex=True)\n",
        "            df_mojo[col] = pd.to_numeric(df_mojo[col], errors='coerce')\n",
        "\n",
        "        # Select only what we need\n",
        "        final_df = df_mojo[['title', 'domestic_opening']]\n",
        "\n",
        "        # Show sample\n",
        "        print(final_df.head())\n",
        "\n",
        "        # Save\n",
        "        final_df.to_csv('domestic_openings.csv', index=False)\n",
        "        print(\"\\nSaved to 'domestic_openings.csv'\")\n",
        "\n",
        "    else:\n",
        "        print(\"Could not identify the correct table. The column names might have changed.\")\n",
        "else:\n",
        "    print(f\"Failed to connect. Status: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9l7nYHzAkXj",
        "outputId": "22747c1f-2f14-41b9-dd4f-31e086d650cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-861769936.py:17: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  tables = pd.read_html(response.text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 tables on the page.\n",
            "Success! Data table found.\n",
            "                                        title  domestic_opening\n",
            "0                           Avengers: Endgame         357115007\n",
            "1                     Spider-Man: No Way Home         260138569\n",
            "2                      Avengers: Infinity War         257698183\n",
            "3  Star Wars: Episode VII - The Force Awakens         247966675\n",
            "4     Star Wars: Episode VIII - The Last Jedi         220009584\n",
            "\n",
            "Saved to 'domestic_openings.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. LOAD BOTH DATASETS\n",
        "# If your original file is named something else, change 'movies.csv' below\n",
        "df_features = pd.read_csv('movies.csv')\n",
        "df_target = pd.read_csv('domestic_openings.csv')\n",
        "\n",
        "print(f\"Original Features: {len(df_features)} movies\")\n",
        "print(f\"Scraped Targets:   {len(df_target)} movies\")\n",
        "\n",
        "# 2. CLEAN TITLES FOR BETTER MATCHING\n",
        "# Small differences like \"Avatar \" vs \"avatar\" can break the merge.\n",
        "# We strip whitespace and make everything lowercase to maximize matches.\n",
        "df_features['title_clean'] = df_features['title'].str.strip().str.lower()\n",
        "df_target['title_clean'] = df_target['title'].str.strip().str.lower()\n",
        "\n",
        "# 3. MERGE THE DATA\n",
        "# We use an 'inner' join. This means we only keep movies that exist in BOTH files.\n",
        "# We need both: Budget (from file 1) AND Opening Revenue (from file 2) to train.\n",
        "df_merged = pd.merge(df_features, df_target, on='title_clean', how='inner')\n",
        "\n",
        "# 4. CLEANUP\n",
        "# The merge might create duplicate columns (like title_x and title_y). Let's tidy up.\n",
        "# We keep the original 'title_x' as the main title.\n",
        "df_merged = df_merged.rename(columns={'title_x': 'title'})\n",
        "\n",
        "# specific columns we want to keep for training\n",
        "cols_to_keep = ['title', 'budget', 'genres', 'domestic_opening', 'director_name']\n",
        "\n",
        "# Check if these columns exist (to avoid errors if your CSV is slightly different)\n",
        "available_cols = [c for c in cols_to_keep if c in df_merged.columns]\n",
        "final_df = df_merged[available_cols]\n",
        "\n",
        "print(f\"\\n--- Merge Complete ---\")\n",
        "print(f\"Successfully matched: {len(final_df)} movies.\")\n",
        "print(f\"Data Preview:\")\n",
        "print(final_df.head())\n",
        "\n",
        "# 5. SAVE FINAL DATASET\n",
        "final_df.to_csv('training_data_final.csv', index=False)\n",
        "print(\"\\nSaved as 'training_data_final.csv'. You are ready to train!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzEtbppzBRoy",
        "outputId": "78b218a5-0a7d-4a9b-f529-c8911f1abf9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Features: 4598 movies\n",
            "Scraped Targets:   200 movies\n",
            "\n",
            "--- Merge Complete ---\n",
            "Successfully matched: 188 movies.\n",
            "Data Preview:\n",
            "                      title     budget  \\\n",
            "0                    Avatar  237000000   \n",
            "1         Avengers: Endgame  356000000   \n",
            "2  Avatar: The Way of Water  350000000   \n",
            "3    Avengers: Infinity War  300000000   \n",
            "4   Spider-Man: No Way Home  200000000   \n",
            "\n",
            "                                              genres  domestic_opening  \\\n",
            "0  ['Action', 'Adventure', 'Fantasy', 'Science Fi...          77025481   \n",
            "1         ['Adventure', 'Science Fiction', 'Action']         357115007   \n",
            "2         ['Action', 'Adventure', 'Science Fiction']         134100226   \n",
            "3         ['Adventure', 'Action', 'Science Fiction']         257698183   \n",
            "4         ['Action', 'Adventure', 'Science Fiction']         260138569   \n",
            "\n",
            "   director_name  \n",
            "0  James Cameron  \n",
            "1  Anthony Russo  \n",
            "2  James Cameron  \n",
            "3      Joe Russo  \n",
            "4      Jon Watts  \n",
            "\n",
            "Saved as 'training_data_final.csv'. You are ready to train!\n"
          ]
        }
      ]
    }
  ]
}